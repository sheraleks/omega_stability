{
 "cells": [
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": [
    "# Загрузим данные с помощью модуля Pandas в объект DataFrame\n",
    "import pandas as pd\n",
    "omega_stability = pd.read_csv('omega_stability.csv')\n",
    "\n",
    "# Проведем первичную обработку данных\n",
    "omega_stability = omega_stability.T\n",
    "omega_stability = omega_stability.drop(index = \"Name\")\n",
    "omega_stability.columns = [\"Omega stability\", \"Survival time\"]\n",
    "\n",
    "# Преобразуем значения ячеек в числовые\n",
    "omega_stability[\"Omega stability\"] = omega_stability[\"Omega stability\"].astype(float)\n",
    "omega_stability[\"Survival time\"] = omega_stability[\"Survival time\"].astype(float)\n",
    "\n",
    "x = omega_stability[\"Omega stability\"].values\n",
    "y = omega_stability[\"Survival time\"].values\n",
    "\n",
    "# Проведем визуализацию\n",
    "omega_stability.plot(kind=\"scatter\", x=\"Omega stability\", y=\"Survival time\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "# Построение LTS-оценки\ndef c_step(x, y, x0, model_func, tolerance, max_iter, h0):\n    import math\n    import random\n    import numpy as np\n    from scipy.optimize import least_squares\n    from scipy.optimize import curve_fit \n    residual_func = lambda a, x, y: model_func(x, a) - y\n    i = 1\n    H1 = random.sample(range(len(x)), h0)\n    Q1 = 9999999\n    prev = 0\n    error = abs(Q1-prev)\n    theta = []\n    # Получение x0\n    x0 = least_squares(residual_func, x0, loss=\"linear\", args=(x, y)).x\n    while error > tolerance and i < max_iter:\n        theta = least_squares(residual_func, x0, loss=\"linear\", args=(x[H1], y[H1])).x\n        est = model_func(x, theta)\n        e = y - est\n        prev = Q1\n        Q1 = sum(e**2)\n        error = abs(Q1 - prev)\n        pi = np.argsort(np.abs(e))\n        H1 = pi[:h0]\n        i += 1\n        #print(error)\n    return theta",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "def loo_cross_validation_lts(x, y, model_func, h0):\n    import math\n    import numpy as np\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import LeaveOneOut\n    loo = LeaveOneOut()\n    predicts = []    \n    for train, test in loo.split(x):\n        x_train = x[train]\n        y_train = y[train]\n        x_test = x[test]\n        y_test = y[test]\n        a = c_step(x, y, [0, 0, 0, 0], model_func, 1e-7, 500, h0)\n        predict = model_func(x_test, a)\n        predicts.append(predict)\n    rmse = math.sqrt(mean_squared_error(y, predicts))\n    return rmse, a",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "def cube_func(x, a):\n    return a[0] + a[1] * x + a[2] * x**2 + a[3] * x**3\ndef cube_func_ols(x, a0, a1, a2, a3):\n    return a0 + a1 * x + a2 * x**2 + a3 * x**3",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "d = {}\ncv_m, a_m = 300, []\nh0 = 0\nfor i in range(22, 40):\n    cv, a = loo_cross_validation_lts(x, y, cube_func, i)\n    d[i] = a\n    if cv < cv_m:\n        cv_m = cv\n        a_m = a\n        h0 = i\n    print(\"i \" + str(i))\n    print(cv)\nprint(\"min cv \", cv_m)\nprint(\"h0\", h0)\nprint(a_m)",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "i 22\n5.420191192809716\n",
      "i 23\n9.84152174127635\n",
      "i 24\n6.995632620424497\n",
      "i 25\n3.4137603642886636\n",
      "i 26\n3.6382498465488853\n",
      "i 27\n4.6543846453215165\n",
      "i 28\n3.568676923030016\n",
      "i 29\n3.607326079834195\n",
      "i 30\n3.6375599791058293\n",
      "i 31\n3.802599810514567\n",
      "i 32\n3.5726083894093943\n",
      "i 33\n3.727328034683732\n",
      "i 34\n3.690986347381327\n",
      "i 35\n3.5736170245236325\n",
      "i 36\n3.5625996046079997\n",
      "i 37\n3.550019357946926\n",
      "i 38\n3.470243495076802\n",
      "i 39\n3.444861579883074\nmin cv  3.4137603642886636\nh0 25\n[ 15.95804684 124.23325072 353.48388773 325.50331668]\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt\nimport numpy as np\nfig, ax = plt.subplots()\nax.scatter(x, y)\nx_plot = np.linspace(-0.5, 0.5, num=1000)\n# ols\nfrom scipy.optimize import curve_fit\na, _ = curve_fit(cube_func_ols, x, y)\nprint(a)\ny_plot = cube_func(x_plot, a)\nax.plot(x_plot, y_plot, c=\"r\")\n#ax.legend((\"ols\", \"data\"))\n\n#37\n#h0 = 37\ny_plot = cube_func(x_plot, d[h0])\nax.plot(x_plot, y_plot, c=\"g\")\nax.legend((\"ols\", h0, \"data\"))",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "# M-estimators",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "scrolled": true,
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "from scipy.optimize import least_squares\nresidual_func = lambda a, x, y: cube_func(x, a) - y\ntheta = least_squares(residual_func, [13.2172348, 59.92121269, -14.74252034, -249.17161382], loss=\"huber\", args=(x, y))\na_m = theta.x\nfig, ax = plt.subplots()\nax.scatter(x, y)\nx_plot = np.linspace(-0.5, 0.5, num=1000)\ny_plot = a_m[0] + a_m[1]*x_plot + a_m[2]*x_plot**2 + a_m[3]*x_plot**3\nax.plot(x_plot, y_plot)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "def loo_cross_validation_robust(x, y, model_func):\n    import math\n    from scipy.optimize import curve_fit \n    import numpy as np\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import LeaveOneOut\n    residual_func = lambda a, x, y: model_func(x, a) - y\n    loo = LeaveOneOut()\n    predicts = []    \n    for train, test in loo.split(x):\n        x_train = x[train]\n        y_train = y[train]\n        x_test = x[test]\n        y_test = y[test]\n        robust = least_squares(residual_func, [13.2172348, 59.92121269, -14.74252034, -249.17161382], f_scale = 0.1, loss='arctan', args=(x_train, y_train))\n        param = robust.x\n        predict = model_func(x_test, param)\n        predicts.append(predict)\n    rmse = math.sqrt(mean_squared_error(y, predicts))\n    return rmse",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "print(loo_cross_validation_robust(x, y, cube_func))",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "#----------------------------------------------------------------------------------------------------",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "def lin_ols(x, a0, a1):\n    return a0 + a1*x;",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "# Новая LOO кросс-валидация\ndef new_loo_cv(x, y, model_func):\n    import math\n    from scipy.optimize import curve_fit \n    import numpy as np\n    SE = 0\n    for i in range(len(x)):\n        test_x = x[i]\n        test_y = y[i]\n        x_new = np.delete(x, i)\n        y_new = np.delete(y, i)\n        a, _ = curve_fit(model_func, x_new, y_new)\n        exact_val = model_func(test_x, a[0], a[1])\n        SE+=(test_y - exact_val)**2\n    RMSE = math.sqrt(SE/len(x))\n    return RMSE",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "print(new_loo_cv(x, y, cube_func_ols))",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "print(new_loo_cv(x, y, lin_ols))",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "# Новая LOO кросс-валидация для LTS\ndef new_loo_cv_lts(x, y, model_func, h0):\n    import math\n    from scipy.optimize import curve_fit \n    import numpy as np\n    SE = 0\n    for i in range(len(x)):\n        test_x = x[i]\n        test_y = y[i]\n        x_new = np.delete(x, i)\n        y_new = np.delete(y, i)\n        a = c_step(x_new, y_new, [0, 0, 0, 0], model_func, 1e-7, 500, h0)\n        exact_val = model_func(test_x, a)\n        SE+=(test_y - exact_val)**2\n    RMSE = math.sqrt(SE/len(x))\n    return (RMSE, a)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "for h in range(20, 39):\n    print(h)\n    print(new_loo_cv_lts(x, y, cube_func, h))",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "# Новая LOO кросс-валидация для LTS\ndef new_loo_cv_robust(x, y, model_func):\n    #from IPython.core.debugger import set_trace\n    import math\n    from scipy.optimize import curve_fit \n    import numpy as np\n    from scipy.optimize import least_squares\n    SE = 0\n    residual_func = lambda a, x, y: model_func(x, a) - y\n    for i in range(len(x)):\n        test_x = x[i]\n        test_y = y[i]\n        x_new = np.delete(x, i)\n        y_new = np.delete(y, i)\n        #set_trace()\n        ak = least_squares(residual_func, [ 12.90005922,  73.80893852, 122.45713168,  19.40206171], \n                           loss='huber', args=(x_new, y_new)).x\n\n        exact_val = model_func(test_x, ak)\n        SE+=(test_y - exact_val)**2\n    RMSE = math.sqrt(SE/len(x))\n    return (RMSE, ak)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "print(new_loo_cv_robust(x, y, cube_func))",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "from scipy.optimize import least_squares\n#residual_func = lambda a, x, y: cube_func(x, a) - y\n#theta = least_squares(residual_func, [13.2172348, 59.92121269, -14.74252034, -249.17161382], loss=\"huber\", args=(x, y))\na_m = [  12.42743864,   55.43049293,   -5.49440223, -219.91135959]\nfig, ax = plt.subplots()\nax.scatter(x, y)\nx_plot = np.linspace(-0.5, 0.5, num=1000)\ny_plot = a_m[0] + a_m[1]*x_plot + a_m[2]*x_plot**2 + a_m[3]*x_plot**3\nax.plot(x_plot, y_plot)\n\na_m = [ 11.41492391,   50.88183143,    0.8377467 , -177.42188028]\nx_plot = np.linspace(-0.5, 0.5, num=1000)\ny_plot = a_m[0] + a_m[1]*x_plot + a_m[2]*x_plot**2 + a_m[3]*x_plot**3\nax.plot(x_plot, y_plot)\n# оранжевый - LTS",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "M-оценка не дает минимального результата, т.к. LTS на примерно таких же коэффициентах выдаёт ещё большее значение Кросс-Валидации"
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "x_new = x + abs(np.min(x))",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "fig, ax = plt.subplots()\nx_plot = np.linspace(0, 1, num=1000)\ny_plot = weibull([0.5, 5], x_plot)\nax.plot(x_plot, y_plot)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "# теперь подготовим исходные данные \n# выполним сортировку\nx, y = zip(*sorted(zip(x_new, y)))\nx = np.asarray(x)\ny = np.asarray(y)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "# визуадизируем новые данные\nplt.scatter(x, y)\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "plt.plot(x, y)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "def weibull(a, x):\n    return 21.3*(1-np.exp(-(x/a[0])**a[1]))",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "# определим функцию отклонений\ndef weibull_residual(a, x, y):\n    return 21.3*(1-np.exp(-(x/a[0])**a[1])) - y",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "res_robust = least_squares(weibull_residual, [1, 1], loss='huber', args=(x, y)).x",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "res_robust",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "fig, ax = plt.subplots()\nx_plot = x\ny_plot = weibull(res_robust, x_plot)\nax.plot(x_plot, y_plot)\nax.scatter(x, y)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "def new_loo_cv_robust(x, y, model_func):\n    import math\n    import numpy as np\n    from scipy.optimize import least_squares\n    from IPython.core.debugger import set_trace\n    SE = 0\n    residual_func = lambda a, x, y: model_func(a, x) - y\n    for i in range(len(x)):\n        x_test = x[i]\n        y_test = y[i]\n        x_train = np.delete(x, i)\n        y_train = np.delete(y, i)\n        #set_trace()\n        an = least_squares(residual_func, np.ones(2), loss='soft_l1', args=(x_train, y_train)).x\n        exact_val = model_func(an, x_test)\n        SE+=(y_test - exact_val)**2\n    RMSE = math.sqrt(SE/len(x))\n    return (RMSE, an)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "new_loo_cv_robust(x, y, weibull)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": "plt.scatter(x, y)\nx_plot = x\ny_plot = weibull([0.41788069, 3.45097678], x_plot)\nplt.plot(x_plot, y_plot)",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}